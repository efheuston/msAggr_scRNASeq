{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of mouse single cell hematopoietic populations - Hierarchical clustering of index sorted CMP\n",
    "__Author__: Elisabeth F. Heuston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single cell transcriptional and clustering analysis of LSK, CMP, MEP, and GMP data presented in Heuston et al., 2021  \n",
    "\n",
    "raw data are available at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update 2021.07.19:  \n",
    "Previous version (IndexSorted_CMP-archive2.ipynb) was last version to use original 2018/2019 Ct thresholds. New analysis described here:  \n",
    "* Using Fluidigm Real-Time PCR Analysis v4.7.1 by Fluidigm Corporation  \n",
    "* Set Quality Threshold to 0.1, and go through everything that doesn't pass (manually I am very generous)  \n",
    "* Set Ct threshold Method to Auto (Detectors) -- This means that the dRN (Ct theshold) is calculated *per Probe* rather than globally. In my mind this means we can still use probes that may have overall weaker amplification than others  \n",
    "* Rule of thumb is that we pass amplfication that crosses Ct threshold at most twice  \n",
    "* Set baseline correction at Linear (Derivative). This is unchanged from previous analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update:  \n",
    "Previous version (IndexSorted_CMP-archive.ipynb) loaded data, performed normalization, then filtered cells to include only those that were in both Biomark and Flow. This means that empty wells or wells with 2 cells are included in normalization and might offset scales.  \n",
    "Updated version will:  \n",
    "* Load RNA and MFI data  \n",
    "* Filter cells for QC\n",
    "* Filter cells with both RNA and MFI data\n",
    "* Perform RNA and MFI normalizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workbook setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter, ExcelFile\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import DivergingNorm\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from pylab import savefig\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import os\n",
    "import re\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_probe_statistics(df, sheetname, writer):\n",
    "    stats_table=pd.DataFrame()\n",
    "    stats_table['Failed Probe'] = df.sum(axis=1)==0\n",
    "    stats_table['sum'] = df.sum(axis=1).round(2)\n",
    "    stats_table['min Ct'] = df.min(axis=1).round(2)\n",
    "    stats_table['max Ct'] = df.max(axis=1).round(2)\n",
    "    stats_table['mean Ct'] = biomark_ctIndexed.mean(axis=1).round(2)\n",
    "    stats_table['median Ct'] = df.median(axis=1).round(2)\n",
    "    stats_table['Ct std'] = df.std(axis=1).round(2)\n",
    "    stats_table.to_excel(writer, sheetname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply_ct_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ct_limits(x, lowerlimit, upperlimit):\n",
    "    if x < lowerlimit or x > upperlimit:\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dCt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dCt (plate, ref_list = [\"Actb\", \"B2m\", \"Cd117\"]):\n",
    "\n",
    "    failed = []\n",
    "    [failed.append(x) for x in ref_list if not rna_df.columns.str.contains(x).any()]\n",
    "    \n",
    "    # Test if table in correct format\n",
    "    if bool(failed):\n",
    "        print('None of', failed, 'found in columns')        \n",
    "        \n",
    "    refCt = plate[plate[ref_list] > 0].mean(axis = 1)\n",
    "    plate = plate.subtract(refCt, axis = 0)\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cell_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_filter(plate, lowerlimit = 8, upperlimit = 40, min_passed_tests = 30, min_passed_references = 2, avg_ct_thresh = None, transpose_plate = True):\n",
    "    \n",
    "    # Read plate\n",
    "    plate.columns = ['Well ID', 'Probe', 'Ct']\n",
    "    plate['Ct'] = plate['Ct'].replace(999.0, np.nan) # replace fails with NA\n",
    "    \n",
    "    # Filter cells\n",
    "    plate['Ct'] = plate['Ct'].apply(lambda x: apply_ct_limits(x, lowerlimit, upperlimit)) # apply Ct threshold limits\n",
    "    plate = plate.set_index(['Well ID', 'Probe']) # clean index\n",
    "    plate = plate.unstack(level = 'Well ID') # clean index\n",
    "    plate.columns = plate.columns.droplevel() # clean index\n",
    "    plate = plate.transpose() # Sets cells to index\n",
    "    \n",
    "    if not min_passed_tests == None: # Drop cells where fewer than X probes passed\n",
    "        plate = plate[plate[plate > 0].count(axis = 1) >= min_passed_tests] \n",
    "    \n",
    "    if not min_passed_references == None: # Drop cells where fewer than X reference probes passed\n",
    "        plate = plate[plate[plate[[\"Actb\", \"B2m\", \"Cd117\"]] > 0].count(axis = 1) >= min_passed_references] \n",
    "        \n",
    "    if not avg_ct_thresh == None: # Drop cells where mean Ct > theshold\n",
    "        plate = plate[plate[plate > 0].mean(axis = 1) >= avg_ct_thresh] \n",
    "        \n",
    "        \n",
    "    plate = plate.replace(0, np.nan) # replace all 0 values with NA\n",
    "\n",
    "    if transpose_plate == False:\n",
    "        plate = plate.transpose()\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probe_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_filter(plate, pct_nan_allowed = .2):\n",
    "    plate = plate.dropna(thresh=int(len(plate)*pct_nan_allowed), axis = 1)\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dCt_xprsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dCt_xprsn(plate):\n",
    "    plate = 2**(plate*-1)\n",
    "    plate = plate.replace(np.nan, 0)\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zscore_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_norm (plate):\n",
    "    \n",
    "    #Calculate z_score\n",
    "    row_mean = plate.mean(axis = 1, skipna = True)\n",
    "    row_std = plate.std(axis = 1, skipna = True)\n",
    "    plate = plate.sub(row_mean, axis = 0)\n",
    "    plate = plate.div(row_std, axis = 0)\n",
    "\n",
    "    return plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_norm(plate):\n",
    "    \n",
    "    # Calculate z_score (x - mean/stdev)\n",
    "    column_mean = plate.mean(axis = 0, skipna = True)\n",
    "    column_std = plate.std(axis = 0, skipna = True)\n",
    "    plate = plate.sub(column_mean, axis = 1)\n",
    "    plate = plate.div(column_std, axis = 1)\n",
    "    \n",
    "    # Replace 0 with NA\n",
    "    plate = plate.replace(0, np.nan)\n",
    "    return plate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning_flow(indexStats_column):\n",
    "    if indexStats_column.mean() !=0:\n",
    "        flow_bins = [-np.inf, 0, indexStats_column.mean(), indexStats_column.mean()+2*indexStats_column.std(), np.inf]\n",
    "        flow_labels = [0,1,2,3]\n",
    "    elif indexStats_column.mean() == 0:\n",
    "        if indexStats_column.std() ==0:\n",
    "            flow_bins = [-np.inf, np.inf]\n",
    "            flow_labels = [0]\n",
    "        elif indexStats_column.std() !=0:\n",
    "            flow_bins = [-np.inf, indexStats_column.mean(), indexStats_column.mean()+2*indexStats_column.std(), np.inf]\n",
    "            flow_labels = [0, 1, 2]\n",
    "    else:\n",
    "        return\n",
    "    binned_flow = pd.cut(indexStats_column, bins = flow_bins, labels = flow_labels)\n",
    "    return pd.Series(binned_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign_plate_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_plate_id(col, sortdate, sort_dict):\n",
    "    pid = ''\n",
    "    if sortdate in ['010319', '121218', '020119']:\n",
    "        if any(col.str.contains('01')):\n",
    "            pid = sort_dict[sortdate][0]\n",
    "        elif any(col.str.contains('07')):\n",
    "            pid = sort_dict[sortdate][1]\n",
    "        else:\n",
    "            pid = 'unknown'\n",
    "    elif sortdate == '090618':\n",
    "        if any(col.str.contains('01')):\n",
    "            pid = sort_dict[sortdate][1]\n",
    "        elif any(col.str.contains('07')):\n",
    "            pid = sort_dict[sortdate][0]\n",
    "        else:\n",
    "            pid = 'unknown'\n",
    "    else:\n",
    "        pid = \"notInSortList\"\n",
    "    return pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_colors = sns.cubehelix_palette(n_colors = 10, start = 0.5, rot = -0.8, gamma = 0.6, hue = 1.00, light = .9, dark = 0, reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read RNA and MFI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plate translations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plate|PlateID|SortDate|RunDate|Pop1|Pop2| \n",
    "-----|-------|--------|-------|----|----|\n",
    "Plate1|LM_Plate1|01.03.19|02.15.19|CMP|MEP|  \n",
    "Plate2|LM_Plate2|12.12.18|02.26.19|CMP|LSK|  \n",
    "Plate3|LM_Plate3|01.03.19|03.06.19|MEP|CMP|  \n",
    "Plate4|LM_Plate4|12.12.18|03.13.19|LSK|CMP|  \n",
    "Plate5|LM_Plate5|01.10.19|03.18.19|LSK|LSK|  \n",
    "Plate6|LM_Plate6|02.01.19|03.20.19|CMP|MEP|  \n",
    "Plate7|LM_Plate7|02.01.19|08.06.19|MEP|CMP|  \n",
    "Plate8|LM_Plate8|02.06.19|08.07.19|LSK|MEP|  \n",
    "Plate9|LM_Plate9|01.23.19|08.09.19|LSK|MEP|  \n",
    "Plate10|LM_Plate10|02.06.19|08.14.19|MEP|LSK|  \n",
    "Plate11|LM_Plate11|01.23.19|08.19.19|MEP|LSK|  \n",
    "Plate12|BP1|09.06.18|10.23.18|LSK|CMP|  \n",
    "Plate13|BP2|09.06.18|10.23.18|CMP|LSK|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open every sheet in excel file, keep only rows where name contains CMP, then do basic QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_biomark = pd.ExcelFile(\"/Users/heustonef/Desktop/Github/MouseSingleCellPaper/BioMark_CT.xlsx\")\n",
    "\n",
    "rna_list = []\n",
    "for sheet in excel_biomark.sheet_names:\n",
    "    plate_data = pd.read_excel(excel_biomark, sheet_name=sheet, skiprows=11, usecols=\"B, E, G\")\n",
    "    plate_data = plate_data[plate_data[\"Name\"].str.contains(\"CMP\")]\n",
    "    if not plate_data.empty:\n",
    "        plate_data[\"Name\"] = plate_data[\"Name\"] + '_' + ''.join(re.search('(\\w)[a-zA-Z]*(\\d+)', sheet).groups([0, 2])).lower()\n",
    "        plate_data = cell_filter(plate_data, lowerlimit=8, upperlimit=40, min_passed_tests=2, avg_ct_thresh=None, transpose_plate=True)\n",
    "        rna_list.append(plate_data)\n",
    "        \n",
    "rna = pd.concat(rna_list, axis = 0, ignore_index = False)\n",
    "rna = probe_filter(rna, pct_nan_allowed=0.2)\n",
    "\n",
    "print(\"Number of cells:\", rna.shape[0])\n",
    "print(\"Number of probes:\", rna.shape[1])\n",
    "rna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_idx = set(rna.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_dict = {'010319':['p1', 'p3'], \n",
    "            '121218': ['p2', 'p4'],\n",
    "            '020119': ['p6', 'p7'],\n",
    "            '090618': ['p12', 'p13'],\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluor_dict = {'FITC-A': 'Cd41', \n",
    "              'PerCP-A': 'Cd135', \n",
    "              'PE-A': 'Cd123', \n",
    "              'PE-Cy7-A': 'Cd48', \n",
    "              'APC-A': 'Cd34', \n",
    "              'APC-Alexa 700-A': 'Cd16/32', \n",
    "              'BV510-A': 'Viability', \n",
    "              'BV650-A': 'Cd150', \n",
    "              'BV786-A': 'Cd36', \n",
    "              'PI-A': 'Cd117',\n",
    "              'PerCP-Cy5-5-A': 'Cd135',\n",
    "              'BV421-A': 'Cd9',\n",
    "              'BV750-A': 'Cd36', \n",
    "              'PE-CF594-A': 'Cd117', \n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ab panel for CMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antibody|Fluor|Equivalencies|\n",
    "--------|-----|-------------|\n",
    "Cd36|SB780|BV786|\n",
    "Flk2/Flt3/Cd135|PerCp-eFluor710|PerCpCy5.5|\n",
    "Cd48|PE-Cy7|N/A|\n",
    "Cd9|eFluor450|BV421/SB436|\n",
    "Cd34|eFluor660|APC|\n",
    "Cd123|PE|N/A|\n",
    "cKit/Cd117|PE-eFluor610|PI|\n",
    "Cd16/32|AF700|APC-Alexa700|\n",
    "Cd41|Fitc|N/A|\n",
    "Cd150|SB645|BV650|\n",
    "Viability|eFluor506|AmCyan|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read MFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plates_01_03 = \"/Users/heustonef/Desktop/CMPSubpops/FlowData/010319 EH CMP extended violet panel/\"\n",
    "plates_02_04 = \"/Users/heustonef/Desktop/CMPSubpops/FlowData/121218 EH CMP extended violet panel/\"\n",
    "plates_12_13 = \"/Users/heustonef/Desktop/CMPSubpops/FlowData/090618 CMP Ext Vio FWDS 070/\"\n",
    "plates_06_07 = \"/Users/heustonef/Desktop/CMPSubpops/FlowData/020119 EH CMP extended violet panel/\"\n",
    "\n",
    "cmp_plates = [plates_01_03, plates_02_04, plates_06_07, plates_12_13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = []\n",
    "for plate in cmp_plates:\n",
    "    for (dirpath, dirnames, filenames) in os.walk(plate):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('Well.csv'): \n",
    "                list_of_files.append(os.sep.join([dirpath, filename]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that unlike RNA, MFI data just needs to be read in. Filtering based on detection of non-CMP markers (i.e., cKit, Cd16/32, Cd34, viability) was done in Flow Jo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mfi = pd.DataFrame()\n",
    "mfi_list = []\n",
    "\n",
    "leading_zeros = re.compile('(?<=[a-z])0(?=[0-9])')\n",
    "\n",
    "for file in list_of_files:\n",
    "    df = pd.read_csv(file, usecols=[0, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17])\n",
    "    df = df.rename(columns = fluor_dict)\n",
    "    sortdate = re.search('(^\\d+).*(\\d{3}_\\d{3})', os.path.basename(file)).group(1)\n",
    "    plateid = re.search('(^\\d+).*(\\d{3}_\\d{3})', os.path.basename(file)).group(2)\n",
    "    pid = assign_plate_id(df.Well, sortdate, sort_dict)\n",
    "    df['sortdate'] = sortdate\n",
    "    df['plateid'] = plateid\n",
    "    df['pid'] = pid\n",
    "    df['Well'] = df['Well'].str.lower()\n",
    "    df['Well'] = df['Well'].map((lambda x: re.sub(leading_zeros, '', x)))\n",
    "    mfi_list.append(df)\n",
    "mfi = pd.concat(mfi_list, axis = 0, ignore_index=True)\n",
    "\n",
    "mfi = mfi.sort_values(['sortdate', 'Well', 'plateid'])\n",
    "mfi = mfi.drop_duplicates(subset = ['Well', 'sortdate'], keep = 'first')\n",
    "mfi.index = 'CMP_' + (mfi['Well'].str.cat(mfi['pid'], sep = '_')).astype('str')\n",
    "mfi = mfi.drop(['Cd16/32', 'Viability'], axis = 1)\n",
    "for fluor in mfi.columns:\n",
    "    if re.search(r'\\d+$', fluor):\n",
    "        mfi = mfi.rename(columns = {fluor: (fluor + 'pos')})\n",
    "\n",
    "mfi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and assign missing pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_list = np.where(mfi.pid == 'unknown')[0].tolist()\n",
    "unk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unk in unk_list:\n",
    "    print(unk)\n",
    "    print(mfi.iloc[(unk-1):(unk+2), [0, 10, 11, 12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi = mfi.rename(index = {'CMP_d9_unknown': 'CMP_d9_p7'})\n",
    "mfi.pid[142] = 'p7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi_idx = set(mfi.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter RNA and MFI cell sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersect RNA and MFI indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_idx = rna_idx.intersection(mfi_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shared_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA df\n",
    "Keep only cells in RNA and MFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_df = rna.loc[rna.index.isin(shared_idx), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rna_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check standard deviation of probes compared to what we're using now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_df = dCt(rna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(x, '\\t',  round(rna_df[x].std(), 3)) for x in rna_df.columns if rna_df[x].std() < max(rna_df['Actb'].std(), rna_df['B2m'].std(), rna_df['Cd117'].std())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like in addition to Actb, B2m, and Cd117, there are 4 additional probes (Cst3, Hp, Ifitm1, Prtn3) with low standard deviation. Might add these later.  \n",
    "\n",
    ">**NB:**  \n",
    "These are low std *after* dCt calculation. The list is much longer if you test before you do the correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dCt normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using deltaCt method:  \n",
    "> refGenes = Act, B2m, Cd117  \n",
    "> refCt = average(Actb, B2m, Cd117) (for refGenes > 0)  \n",
    "> deltaCt(gene) = Ct(gene) - refCt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So deltaCt method normalizes individual cells to reference genes, so plate normalization is not necessary.  \n",
    "Probe filtering has removed uninformative probes.  \n",
    "For the moment let's ignore flow data (which probably has to be reanalyzed) and cluster just the cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2^-dCt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta delta Ct needs comparison against a control, but we don't have (i.e.,) treated vs untreated. Could use ref genes again, but this is probably double-normalizing.  \n",
    "Let's just do expression of the dCts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_xprsn = dCt_xprsn(rna_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional clustering methods:  \n",
    "> single  \n",
    "> complete  \n",
    "> average  \n",
    "> weighted  \n",
    "> centroid  \n",
    "> median  \n",
    "> ward  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(rna_xprsn.transpose(), figsize=(25,15), method = 'average', robust = True, xticklabels = False, yticklabels = True, vmin = 0)\n",
    "sns.clustermap(rna_df.replace(np.nan, 0).transpose(), figsize=(25,15), method = 'average', robust = True, xticklabels = False, yticklabels = True, vmin = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can color individual leaves to show which markers correspond with which celltypes  \n",
    "https://python-graph-gallery.com/405-dendrogram-with-heatmap-and-coloured-leaves/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z_score norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note about z_scores:  \n",
    "> Z scores are: z = (x - mean)/std, so values in each row will get the mean of the row subtracted, then divided by the standard deviation of the row.  \n",
    "> This ensures that each row has mean of 0 and variance of 1.  \n",
    "\n",
    "Either 0 (rows) or 1 (columns):  \n",
    "> 0 = Set the mean of each __gene__ to zero and see which cells express it the most  \n",
    "> 1 = Set the mean of each __cell__ to zero and see which genes are most variable in it  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z score across cells.  \n",
    "Do you do z_score then dCt, or dCt then z_score, or just z_score?  \n",
    "I think z_score is the cell norm method, so will try just z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_zscore = dCt(rna_df)\n",
    "rna_zscore = zscore_norm(rna_zscore)\n",
    "rna_zscore = dCt_xprsn(rna_zscore).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(rna_zscore, figsize=(25,15), method = 'average', robust = True, xticklabels = False, yticklabels = True, vmin = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklear.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess if you assume each plate has the same distribution of cell types, then you can assume that plates represent a gaussian distribution of an expression profile.  \n",
    "So we can scale each plate, which should make inter-plate comparisons more fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Is this normalizing across each cell??__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rna_df_by_pid = rna_df.groupby('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rna_scaled_list = []\n",
    "\n",
    "for pid in rna_df_by_pid.groups.keys():\n",
    "    \n",
    "    df = rna_df_by_pid.get_group(pid).transpose()\n",
    "    df = df.drop('pid', axis = 0)\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(df)\n",
    "    df_scaled = scaler.transform(df)\n",
    "    df_scaled = pd.DataFrame(df_scaled, index = df.index, columns=df.columns)\n",
    "#     ic(df_scaled.shape[0], df_scaled.mean(axis = 0), df_scaled.std(axis = 0))\n",
    "    \n",
    "    rna_scaled_list.append(df_scaled.transpose())\n",
    "    \n",
    "    \n",
    "rna_scaled = pd.concat(rna_scaled_list)\n",
    "# rna_scaled = rna_scaled.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(rna_scaled.transpose(), figsize=(25,15), method = 'ward', robust = True, xticklabels = True, yticklabels = True, vmin = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn.RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_df_by_pid = rna_df.groupby('pid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rna_robust_list = []\n",
    "\n",
    "for pid in rna_df_by_pid.groups.keys():\n",
    "    \n",
    "    df = rna_df_by_pid.get_group(pid).transpose()\n",
    "    df = df.drop('pid', axis = 0)\n",
    "    \n",
    "    scaler = preprocessing.RobustScaler().fit(df)\n",
    "    df_scaled = scaler.transform(df)\n",
    "    df_scaled = pd.DataFrame(df_scaled, index = df.index, columns=df.columns)\n",
    "#     ic(df_scaled.shape[0], df_scaled.mean(axis = 0), df_scaled.std(axis = 0))\n",
    "    \n",
    "    rna_robust_list.append(df_scaled.transpose())\n",
    "    \n",
    "    \n",
    "rna_robust = pd.concat(rna_robust_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(rna_robust.transpose(), figsize=(25,15), method = 'ward', robust = True, xticklabels = True, yticklabels = True, vmin = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RobustScaler is supposed to handle outliers better, but now I get a tv screen. And p13 is clumping like a beast...     \n",
    "__Perform an outlier test before deciding on these results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization notes  \n",
    "[Fluidigm](https://www.fluidigm.com/faq/ge-63) suggests normalizing my _median_ Ct  \n",
    "Should reinvestigate the biomark software itself and make absolutely sure there's no way to normalize through that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFI df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi_df = mfi.loc[mfi.index.isin(shared_idx), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hitogram of unmodified flow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi_by_pid = mfi_df.groupby('pid')\n",
    "mfi_by_pid.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plate in mfi_by_pid.groups.keys():\n",
    "    plot_group = mfi_by_pid.get_group(plate)\n",
    "    plot_group = plot_group.replace(np.nan, 0)\n",
    "    \n",
    "    for array in plot_group.hist(bins = 40, layout = (9, 11), figsize = (50, 50)):\n",
    "        for subplot in array:\n",
    "            subplot.set_ylabel(plate)\n",
    "#             subplot.set_xlim(left = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdbu = sns.diverging_palette(250, 10, s = 100, l=50, sep = 1,  center= \"dark\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFI above background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with zscore norm is that it doesn't necessarily preserve fluourescence distribution  \n",
    "Went throught each experiment and calculated minimum MFI that was still \"positive\" above background (i.e., Cd34 MFI 161 = Cd34- but Cd34 MFI 162 = Cd34+)  \n",
    "For ease, going to just call this \"background\"  \n",
    "Will subtract background from fluor for each experiment, then normalize between 1 and 100 <- this will preserve distribution of \"positive\" values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define backgrounds for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkgd_dict = {'010319': {'Cd34pos': 162, 'Cd117pos': 1200, 'Cd9pos': 1100, 'Cd36pos': 1300, 'Cd41pos': 433, 'Cd48pos': 89, 'Cd123pos': 314, 'Cd150pos': 415, 'Cd135pos': 433},\n",
    "             '020119': {'Cd34pos': 222, 'Cd117pos': 356, 'Cd9pos': 1100, 'Cd36pos': 204, 'Cd41pos': 430, 'Cd48pos': 156, 'Cd123pos': 305, 'Cd150pos': 419, 'Cd135pos': 27},\n",
    "             '090618': {'Cd34pos': 593, 'Cd117pos': 419, 'Cd9pos': 376, 'Cd36pos': 828, 'Cd41pos': 431, 'Cd48pos': 197, 'Cd123pos': 960, 'Cd150pos': 618, 'Cd135pos': 1000},\n",
    "             '121218': {'Cd34pos': 205, 'Cd117pos': 454, 'Cd9pos': 593, 'Cd36pos': 1300, 'Cd41pos': 755, 'Cd48pos': 91, 'Cd123pos': 1600, 'Cd150pos': 439, 'Cd135pos': 445}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi_by_sortdate = mfi_df.groupby('sortdate')\n",
    "mfi_by_sortdate.get_group('010319').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mfi_sortdate_list = []\n",
    "\n",
    "for sortdate in mfi_by_sortdate.groups.keys():\n",
    "    mfi_subbkgd = mfi_by_sortdate.get_group(sortdate)\n",
    "    sortdate_math = bkgd_dict[sortdate]\n",
    "    for fluor in sortdate_math.keys():\n",
    "        \n",
    "        mfi_subbkgd[fluor] = mfi_subbkgd[fluor] - sortdate_math[fluor] # sets min positive value to 0\n",
    "#         ic(fluor, sortdate, \n",
    "#            mfi_subbkgd[fluor].min(), \n",
    "#            mfi_subbkgd[fluor].max()\n",
    "#           )\n",
    "        mfi_subbkgd[fluor] = mfi_subbkgd[fluor].clip(lower = 0)\n",
    "        mfi_subbkgd[fluor] = mfi_subbkgd[fluor]/mfi_subbkgd[fluor].max()\n",
    "    \n",
    "    mfi_sortdate_list.append(mfi_subbkgd)\n",
    "mfi_sortdate = pd.concat(mfi_sortdate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi_sortdate.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mfi_sortdate_by_sortdate = mfi_sortdate.groupby('sortdate')\n",
    "for plate in mfi_sortdate_by_sortdate.groups.keys():\n",
    "    plate_df = mfi_sortdate_by_sortdate.get_group(plate)\n",
    "    plate_df = plate_df.drop(['Well', 'sortdate', 'plateid', 'pid'], axis = 1)\n",
    "#     ic(plate, \n",
    "#        plate_df.min(), \n",
    "#        plate_df.max()\n",
    "#       )\n",
    "    plate_df = pd.melt(plate_df).rename(columns={'variable': 'fluor', 'value': 'norm_mfi'})\n",
    "    \n",
    "    # create figures\n",
    "    g = sns.FacetGrid(plate_df, col = 'fluor')\n",
    "    g.fig.set_size_inches(30, 7)\n",
    "    g.map(sns.histplot, 'norm_mfi', bins = 40, stat = 'probability', kde = True, line_kws = {'linewidth':4})\n",
    "    g.set_axis_labels(y_var=plate)\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(top = 0.3)\n",
    "    \n",
    "#     #save figures\n",
    "#     save_title = ''.join(('bkgd_norm_mfi-biomarkCells-', plate, '.png'))\n",
    "#     plt.savefig(save_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdbu = sns.diverging_palette(250, 10, s = 100, l=50, sep = 1,  center= \"dark\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi_mtx = mfi_sortdate[['Cd41pos', 'Cd135pos', 'Cd9pos', 'Cd150pos', 'Cd36pos', 'Cd34pos', 'Cd123pos', 'Cd117pos', 'Cd48pos']].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(mfi_mtx.transpose(), figsize=(25,10), method = 'ward', robust = True, xticklabels = True, yticklabels = True, vmin = 0, vmax = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use mfi_sortdate because want to keep batch info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi_pca = mfi_sortdate.drop(['Well', 'sortdate', 'plateid'], axis = 1)\n",
    "mfi_pca['pid'] = mfi['pid'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "# pca_result = pca.fit_transform(cluster_df.iloc[:, :-1].values)\n",
    "pca_result = pca.fit_transform(mfi_pca.values)\n",
    "pca_df = mfi_pca.copy()\n",
    "pca_df['pca-one'] = pca_result[:,0]\n",
    "pca_df['pca-two'] = pca_result[:,1] \n",
    "pca_df['pca-three'] = pca_result[:,2]\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2)\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.scatterplot(\n",
    "#     ax = axes[0], \n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"pid\",\n",
    "    palette=sns.color_palette(\"hls\", len(pca_df['pid'].unique())),\n",
    "    data=pca_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7, \n",
    "    s = 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Biomark and MFI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 ways to do this:  \n",
    "> Combine the data then cluster, letting flow marker contribute to hierarchy  \n",
    "> Cluster the biomark data, then tack on the appropriate flow markers  \n",
    "\n",
    "Easiest should be to combine the data then cluster, so I'll start there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pd.merge(how = 'left')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_zscoreT = rna_zscore.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = rna_zscoreT.merge(mfi_mtx, how='left', right_on=mfi_mtx.index, left_index=True).drop(\"key_0\", axis = 1).transpose()\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number cells per plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = combined_df.transpose().copy()\n",
    "pid = [str(re.match('.*?([0-9]+)$', x).group(1)) for x in grouped.index]\n",
    "grouped['pid'] = pid\n",
    "grouped_by_pid = grouped.groupby('pid')\n",
    "for plate in grouped_by_pid.groups.keys():\n",
    "    ic(plate, grouped_by_pid.get_group(plate).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined cluster:  co-sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster on biomark and mfi; mfi distributed through rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(combined_df, figsize=(25,15), method = 'ward', robust = True, xticklabels = True, yticklabels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined cluster: separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster on rna and mfi; plot with rna on top and mfi on bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_rows = sns.clustermap(combined_df, figsize=(.5,.5), method = 'ward', robust = True, xticklabels = False, yticklabels = False, vmin = 0).dendrogram_row.reordered_ind\n",
    "hm_cols = sns.clustermap(combined_df, figsize=(.5, .5), method = 'ward', robust = True, xticklabels = False, yticklabels = False, vmin = 0).dendrogram_col.reordered_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the gene order from clustered rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_order = []\n",
    "for pos in hm_rows:\n",
    "    newrow = combined_df.index[pos]\n",
    "    row_order.append(newrow)\n",
    "rna_order = [x for x in row_order if not x.endswith('pos')]\n",
    "mfi_order = [x for x in row_order if x.endswith('pos')]\n",
    "combined_rna = combined_df[combined_df.index.isin(rna_order)]\n",
    "combined_mfi = combined_df[combined_df.index.isin(mfi_order)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get cell order from clustered rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = []\n",
    "for pos in hm_cols:\n",
    "    newcol = combined_df.columns[pos]\n",
    "    col_order.append(newcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(combined_rna.reindex(index = rna_order, columns=col_order), figsize = (25, 15), method = 'ward', robust = True, xticklabels = False, yticklabels = True, row_cluster=False, col_cluster = False)\n",
    "sns.clustermap(combined_mfi.reindex(index = mfi_order, columns=col_order), figsize = (25, 2.5), method = 'ward', robust = True, xticklabels = False, yticklabels = True, row_cluster=False, cmap = 'viridis', col_cluster = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster columns and rows then add mfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get column and row order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_rows = sns.clustermap(rna_zscore, figsize=(1,1), method = 'ward', robust = True, xticklabels = False, yticklabels = True, vmin = 0).dendrogram_row.reordered_ind\n",
    "hm_cols = sns.clustermap(rna_zscore, figsize=(25,15), method = 'ward', robust = True, xticklabels = True, yticklabels = True, vmin = 0).dendrogram_col.reordered_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the gene order from clustered rna_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_order = []\n",
    "for pos in hm_rows:\n",
    "    newrow = rna_zscore.index[pos]\n",
    "    row_order.append(newrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get cell order from clustered rna_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = []\n",
    "for pos in hm_cols:\n",
    "    newcol = rna_zscore.columns[pos]\n",
    "    col_order.append(newcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reorder mfi columns to match rna_zscore order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(mfi_mtx.transpose().reindex(columns=col_order), figsize=(25,10), method = 'ward', robust = True, xticklabels = False, yticklabels = True, col_cluster=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the whole thing in one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = rna_zscore.reindex(index=row_order, columns=col_order).append(mfi_mtx.transpose().reindex(columns=col_order), sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(combined_df, figsize=(25,15), method = 'ward', robust = True, xticklabels = False, yticklabels = True, row_cluster=False, col_cluster=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because gene range is 0 to +infinity, and because marker range is -infinity to +infinity, graphing them on the same heatmap really throws off the colors. Will plot with rna_zscore heatmap and cell-reordered MFI heatmap (see powerpoint)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster rows-only then add MFI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do it is to cluster by genes, add the MFI, and let the columns cluster using both gene expression *and* mfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get column and row order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_rows = sns.clustermap(rna_zscore, figsize=(1,1), method = 'ward', robust = True, xticklabels = False, yticklabels = True, vmin = 0).dendrogram_row.reordered_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the gene order from clustered rna_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_order = []\n",
    "for pos in hm_rows:\n",
    "    newrow = rna_zscore.index[pos]\n",
    "    row_order.append(newrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get cell order from clustered rna_zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = []\n",
    "for pos in hm_cols:\n",
    "    newcol = rna_zscore.columns[pos]\n",
    "    col_order.append(newcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the whole thing in one df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine the rna_zscore and MFI dfs, preserving rna_zscore's gene row_order. Also reindex columns in both to col_order to make sure they append properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = rna_zscore.reindex(index=row_order, columns=col_order).append(mfi_mtx.transpose().reindex(columns=col_order), sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot combined df to get column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cols = sns.clustermap(combined_df, figsize=(25,15), method = 'ward', robust = True, xticklabels = False, yticklabels = True, row_cluster=True, col_cluster=True).dendrogram_col.reordered_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get cell order from combined clustered df (`combined_cols` is ordered by position, not cell ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = []\n",
    "for pos in combined_cols:\n",
    "    newcol = rna_zscore.columns[pos]\n",
    "    col_order.append(newcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now to make the two pictures, plot rna_zscore and MFI separately, letting the rows in each cluster but preventing column clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reorder rna_zscore columns to match combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(rna_zscore.reindex(columns=col_order), figsize=(25,15), method = 'ward', robust = True, xticklabels = False, yticklabels = True, col_cluster=False, row_cluster = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reorder mfi_mtx columns to match combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(mfi_mtx.transpose().reindex(columns=col_order), figsize=(25,10), method = 'ward', robust = True, xticklabels = False, yticklabels = True, cmap = 'viridis', col_cluster=False, row_cluster = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='PlottSNEData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Data as tSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE of LSK, CMP, and MEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNA zscore + MFI bkgrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_zscoreT = rna_zscore.transpose()\n",
    "combined_df = rna_zscoreT.merge(mfi_mtx, how='left', right_on=mfi_mtx.index, left_index=True).drop(\"key_0\", axis = 1).transpose()\n",
    "cluster_df = combined_df.transpose().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = [str(re.match('.*?([0-9]+)$', x).group(1)) for x in cluster_df.index]\n",
    "cluster_df['pid'] = pid\n",
    "cluster_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "# pca_result = pca.fit_transform(cluster_df.iloc[:, :-1].values)\n",
    "pca_result = pca.fit_transform(cluster_df.values)\n",
    "pca_df = cluster_df.copy()\n",
    "pca_df['pca-one'] = pca_result[:,0]\n",
    "pca_df['pca-two'] = pca_result[:,1] \n",
    "pca_df['pca-three'] = pca_result[:,2]\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2)\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.scatterplot(\n",
    "#     ax = axes[0], \n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"pid\",\n",
    "    palette=sns.color_palette(\"hls\", len(pca_df['pid'].unique())),\n",
    "    data=pca_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7, \n",
    "    s = 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10, 10)).gca(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=pca_df[\"pca-one\"], \n",
    "    ys=pca_df[\"pca-two\"], \n",
    "    zs=pca_df[\"pca-three\"], \n",
    "    c=pca_df[\"pid\"].astype(int), \n",
    "    cmap= 'rainbow', \n",
    "    s = 100\n",
    ")\n",
    "ax.set_xlabel('pca-one')\n",
    "ax.set_ylabel('pca-two')\n",
    "ax.set_zlabel('pca-three')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNA zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = [str(re.match('.*?([0-9]+)$', x).group(1)) for x in rna_zscoreT.index]\n",
    "rna_zscoreT['pid'] = pid\n",
    "rna_zscoreT.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "# pca_result = pca.fit_transform(rna_df.iloc[:, :-1].values)\n",
    "pca_result = pca.fit_transform(rna_zscoreT.values)\n",
    "pca_df = rna_zscoreT.copy()\n",
    "pca_df['pca-one'] = pca_result[:,0]\n",
    "pca_df['pca-two'] = pca_result[:,1] \n",
    "pca_df['pca-three'] = pca_result[:,2]\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2)\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.scatterplot(\n",
    "#     ax = axes[0], \n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"pid\",\n",
    "    palette=sns.color_palette(\"hls\", len(pca_df['pid'].unique())),\n",
    "    data=pca_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7, \n",
    "    s = 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNA xprsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pid = [str(re.match('.*?([0-9]+)$', x).group(1)) for x in rna_xprsn.index]\n",
    "rna_xprsn['pid'] = pid\n",
    "rna_xprsn.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_xprsn.pid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "# pca_result = pca.fit_transform(rna_df.iloc[:, :-1].values)\n",
    "pca_result = pca.fit_transform(rna_xprsn.values)\n",
    "pca_df = rna_xprsn.copy()\n",
    "pca_df['pca-one'] = pca_result[:,0]\n",
    "pca_df['pca-two'] = pca_result[:,1] \n",
    "pca_df['pca-three'] = pca_result[:,2]\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2)\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.scatterplot(\n",
    "#     ax = axes[0], \n",
    "    x=\"pca-two\", y=\"pca-three\",\n",
    "    hue=\"pid\",\n",
    "    palette=sns.color_palette(\"hls\", len(pca_df['pid'].unique())),\n",
    "    data=pca_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7, \n",
    "    s = 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10, 10)).gca(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=pca_df[\"pca-one\"], \n",
    "    ys=pca_df[\"pca-two\"], \n",
    "    zs=pca_df[\"pca-three\"], \n",
    "    c=pca_df[\"pid\"].astype(int), \n",
    "    cmap= 'Set1', \n",
    "    s = 100\n",
    ")\n",
    "ax.set_xlabel('pca-one')\n",
    "ax.set_ylabel('pca-two')\n",
    "ax.set_zlabel('pca-three')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA mfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfi_df = combined_df.transpose().copy()\n",
    "mfi_df = mfi_df.iloc[:, -9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = [str(re.match('.*?([0-9]+)$', x).group(1)) for x in mfi_df.index]\n",
    "mfi_df['pid'] = pid\n",
    "mfi_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "# pca_result = pca.fit_transform(mfi_df.iloc[:, :-1].values)\n",
    "pca_result = pca.fit_transform(mfi_df.values)\n",
    "pca_df = mfi_df.copy()\n",
    "pca_df['pca-one'] = pca_result[:,0]\n",
    "pca_df['pca-two'] = pca_result[:,1] \n",
    "pca_df['pca-three'] = pca_result[:,2]\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2)\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.scatterplot(\n",
    "#     ax = axes[0], \n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"pid\",\n",
    "    palette=sns.color_palette(\"hls\", len(pca_df['pid'].unique())),\n",
    "    data=pca_df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.7, \n",
    "    s = 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10, 10)).gca(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=pca_df[\"pca-one\"], \n",
    "    ys=pca_df[\"pca-two\"], \n",
    "    zs=pca_df[\"pca-three\"], \n",
    "    c=pca_df[\"pid\"].astype(int), \n",
    "    cmap= 'Set1', \n",
    "    s = 100\n",
    ")\n",
    "ax.set_xlabel('pca-one')\n",
    "ax.set_ylabel('pca-two')\n",
    "ax.set_zlabel('pca-three')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "# tsne_results = tsne.fit_transform(cluster_df.iloc[:,:-1])\n",
    "tsne_results = tsne.fit_transform(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = cluster_df.copy()\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"pid\",\n",
    "    palette=sns.color_palette(\"hls\", len(tsne_df.pid.unique())),\n",
    "    data=tsne_df,\n",
    "    legend=\"full\",\n",
    "    alpha=1,\n",
    "    s = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]\n",
    "\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "    mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings\n",
    "    sort_by_target(mnist) # fetch_openml() returns an unsorted dataset\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data / 255.0\n",
    "y = mnist.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df['y'] = y\n",
    "df['label'] = df['y'].apply(lambda i: str(i))\n",
    "X, y = None, None\n",
    "print('Size of the dataframe: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rndperm = np.random.permutation(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gray()\n",
    "fig = plt.figure( figsize=(16,7) )\n",
    "for i in range(0,15):\n",
    "    ax = fig.add_subplot(3,5,i+1, title=\"Digit: {}\".format(str(df.loc[rndperm[i],'label'])) )\n",
    "    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((28,28)).astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndperm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Bioconductor Support Article](https://support.bioconductor.org/p/34182/)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hello Balbine,\n",
    "\n",
    "(I'm forwarding this reply to the Bioconductor list, since it might\n",
    "be of use to people there. Fluidigm seems to be increasing in\n",
    "popularity. A recent discussion, http://article.gmane.org/\n",
    "gmane.science.biology.informatics.conductor/29566/match=htqpcr\n",
    "+fluidigm , might also be of interest to you.)\n",
    "\n",
    "On 24 Jun 2010, at 18:03, ROUSSEL BALBINE wrote:\n",
    "\n",
    "> Hello,\n",
    "> I need advice on normalizing my data.\n",
    ">\n",
    "> With the Fluidigm chips, we can measure expression of 96 genes in\n",
    "> 96 samples on one plate.\n",
    ">\n",
    "> We have 15 plates concerning samples so 1536 samples and 3 sets\n",
    "> concerning genes so we have finally 288 genes.\n",
    ">\n",
    "> Totally, we have 15*3=45 plates\n",
    ">\n",
    "> The problem is that we have not housekeeping genes and no\n",
    "> calibrator samples for each set or for each plate. But we have a\n",
    "> test sample on all plates and a gene on all sets so we can verify\n",
    "> if the normalization takes away much of the impact plates and if we\n",
    "> keep the same information for the same sample or the same gene.\n",
    ">\n",
    "Just to make sure I understand you correctly; you have 3 different\n",
    "plates (lets call them A, B and C) with genes geneA1->geneA96, geneB1-\n",
    " >geneB96 and geneC1>geneC96. Sample X is present on all 45 plates. A\n",
    "single gene, geneY is present on plate types A, B and C. So you\n",
    "should have a single value out of the 96x96 that is identical on all\n",
    "45 plates. So do you have 15x96 = 1440 or 1536 samples in total?\n",
    "\n",
    "For normalising within each plate type you have several options. You\n",
    "can use e.g. rank-invariant normalisation as you suggest, but given\n",
    "that you have an entire sample, i.e. 96 Ct values, that should be the\n",
    "same for all 15 plates, you can also select these 96 values and do a\n",
    "deltaCt normalisation. That corresponds to using these 96 values as\n",
    "\"housekeeping\" genes, since they should be identical across all\n",
    "plates of the same type A, B or C).\n",
    "\n",
    "Normalising across plates A, B and C is a bit trickier. In principle\n",
    "you can designate the single sample x gene value common across all 45\n",
    "plates as a pseudo-housekeeping gene and normalise against that using\n",
    "delta Ct. But because there are no replicates within each plate, if\n",
    "that single reaction didn't work well for whatever reason, it all\n",
    "affect the entire plate after normalisation. Risky! What's the\n",
    "correlation you see for this one Ct values across all 45 plates?\n",
    "Within each of the 3 groups of 45 plates?\n",
    "\n",
    "Alternatively you can also use quantile normalisation as you suggest.\n",
    "Note though that this is a quite \"harsh\" procedure. No-matter what\n",
    "you data looks like to begin with, it will force them into having the\n",
    "same Ct-value distribution. That might be okay if all your genes and\n",
    "samples are completely randomised across all 45 plates. But what if\n",
    "for example 10 samples on one plate (e.g. a particular treatment) all\n",
    "give very high Ct values, whereas another 10 samples (a different\n",
    "treatment) on another plate all give very low Ct values? Then you\n",
    "can't assume that the Ct value distribution on each plate should be\n",
    "identical. In that case a rank-invariant normalisation is probably\n",
    "the safest bet.\n",
    "\n",
    "If you're not going to compare Ct values directly across plate types,\n",
    "such as sampleAA-gene1 versus sample BA-gene4, then technically you\n",
    "wouldn't even have to normalise between plates types A, B and C.\n",
    "Presumably you want to find differential expression of samples across\n",
    "each individual gene, right? Since the same type of gene will always\n",
    "be present on the same type of plate, regardless of sample, you\n",
    "should be okay with just normalising within each A/B/C set.\n",
    "\n",
    "I can't give you any solid advice on what normalisation to do, since\n",
    "it will depend on the distribution of your data, how the samples have\n",
    "been group together on plates and other factors. I would probably\n",
    "first spend a lot of time on initial data QC and comparison, and\n",
    "depending on how the data looks do something along these lines:\n",
    "\n",
    "- Load the three different plate types, A, B and C into separate\n",
    "qPCRset objects. Each object would then consist of 9216 rows (96\n",
    "genes x 96 samples)  and 15 columns (individual plates).\n",
    "- Normalise each of these objects separately, using either quantile\n",
    "normalisation (strictest choice), rank-invariant normalisation or\n",
    "deltaCt normalisation based on the 96 rows corresponding to the\n",
    "sample that have been loaded on all plates.\n",
    "- Combine the three objects together (cbind/rbind), and potentially\n",
    "change the layout (changeCtLayout) so that you have 1 gene per row\n",
    "and 1 sample per column, such that the object can be used for\n",
    "statistical testing.\n",
    "\n",
    "or perhaps:\n",
    "\n",
    "- Load all the plates into a single object with 9206 rows (one 96x96\n",
    "plate) and one row per individual plate = 45.\n",
    "- Do e.g. rank-invariant normalisation across all these.\n",
    "\n",
    "I would probably use some of the diagnostics functions, like\n",
    "clusterCt and plotCtCor both before and after normalisation, to see\n",
    "if the samples group together as expected based on the biology.\n",
    "\n",
    "HTH\n",
    "\\Heidi\n",
    "\n",
    "> So I thought realize normalizations by quantile, or by rank-\n",
    "invariant.\n",
    ">\n",
    "> But I do not know what strategy used because :\n",
    ">\n",
    ">     - I can have a plate effect on the 3 set of genes\n",
    ">     - I can also have a plate effect concerning the different\n",
    "samples\n",
    ">\n",
    "> Is it necessary that I start combining all \"qPCRset objects\" or not?\n",
    ">\n",
    "> For plate 1 and 3 gene sets:\n",
    ">\n",
    "> An object of class \"qPCRset\"\n",
    "> Size:  288 features, 96 samples\n",
    "> Feature types:           P1\n",
    "> Feature names:           AACS AADACL1 ABHD5 ...\n",
    "> Feature classes:\n",
    "> Feature categories:      OK\n",
    "> Sample names:            Sample1 Sample2 Sample3 ...\n",
    ">\n",
    "> For plate 2 and 3 gene sets:\n",
    ">\n",
    "> An object of class \"qPCRset\"\n",
    "> Size:  288 features, 96 samples\n",
    "> Feature types:           P1\n",
    "> Feature names:           AACS AADACL1 ABHD5 ...\n",
    "> Feature classes:\n",
    "> Feature categories:      OK\n",
    "> Sample names:            Sample1 Sample2 Sample3 ...\n",
    ">\n",
    ">\n",
    "> .... up to the plate 15 and 3 gene sets\n",
    ">\n",
    "> > q.features=cbind(qPCRset1,qPCRset2,.....,qPCRset15)\n",
    ">\n",
    "> > q.features\n",
    "> An object of class \"qPCRset\"\n",
    "> Size:  288 features, 1536 samples\n",
    "> Feature types:\n",
    "> Feature names:           AACS AADACL1 ABHD5 ...\n",
    "> Feature classes:\n",
    "> Feature categories:      OK\n",
    "> Sample names:            Sample1 Sample2 Sample3 ...\n",
    ">\n",
    ">\n",
    "> >group=read.table(file=\"group 1536 samples.csv\",h=T,sep=\";\",dec=\".\")\n",
    "> >attach(group)\n",
    "> >groupCID=c(as.character(group$CID))\n",
    "> >sample=c(as.character(group$Subject))\n",
    "> >sampleNames(q.features)=sample\n",
    "> >q.features2=setCategory\n",
    "> (q.features,groups=groupCID,flag=TRUE,flag.out=\"Failed\")\n",
    ">\n",
    ">q.features3=filterCategory(q.features2,na.categories=\"Undetermined\")\n",
    ">\n",
    ">\n",
    ">\n",
    "> do the following strategy may be good? :\n",
    ">\n",
    ">     - to do the quantile normalisation on the 96 samples and 96*3\n",
    "> genes (g=288)\n",
    ">     - then to do the global quantile normalisation on all samples\n",
    "> and all genes\n",
    "> (n=1536, g=288)\n",
    ">\n",
    "> what is with the function \"normalizeCtData()\"  two steps are\n",
    "> performed simultaneously?\n",
    "> if not how can I do? Do I have to do a normalization for each plate\n",
    "> with 3 gene sets? or Is what I specify in my script that it is\n",
    "> these 15 different plates?\n",
    ">\n",
    "> Do you see another strategy more suitable for my data to realize\n",
    "> normalization?\n",
    ">\n",
    "> How would you do?\n",
    ">\n",
    "> Perhaps if we combine the two methods (quantile and rank-invariant):\n",
    ">\n",
    ">     - to do the quantile normalisation on the 96 samples and 96*3\n",
    "> genes (g=288)\n",
    ">     - then to do rank-invariant normalization on all samples and\n",
    "> all genes\n",
    "> (n=1536, g=288)\n",
    ">\n",
    "> How would you do?\n",
    ">\n",
    "> Thanks to your response,\n",
    ">\n",
    "> Balbine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other approaches\n",
    "\n",
    "[Published data analysis for 96.96 Dynamic Array IFC](https://www.gene-quantification.de/livak-methods-59-transcriptional-biomarkers-2013.pdf)  \n",
    "* Data analyzed using Fluidigm Real-Time PCR Analysis software  \n",
    "    * Used linear (derivative) baseline correction method  \n",
    "    * Used Auto (global) Ct threshold method (alt. 0.01)\n",
    "    * Ct range 12 - 28 cycles\n",
    "    * Export Cq values  \n",
    "\n",
    "[G. Guo, Dev. Cell; 18 (2010) 675–685.](https://www.sciencedirect.com/science/article/pii/S1534580710001103#sec4)\n",
    "* Relative expression determined by subtracting Ct value from \"assumed baseline of 28\"\n",
    "* Remove cells with absent/low endogenous controls (~10%)\n",
    "* Normalize these by subtracting average of ActB+GAPDH expression levels\n",
    "\n",
    "[geNorm method](https://doi.org/10.1186/gb-2002-3-7-research0034)\n",
    "* Average control genes using __geometric mean__ (not arithmatic mean)\n",
    "    * genorm support stops with python 2.7 \n",
    "    * R may have an implementation for it via [NormqPCR](https://www.bioconductor.org/packages/release/bioc/html/NormqPCR.html)\n",
    "    \n",
    "[ERgene](https://www.nature.com/articles/s41598-020-75586-5)\n",
    "* Python library to for gene nomralization [github](https://github.com/Starlitnightly/ERgene)\n",
    "\n",
    "[Beth Psaila's Approach](https://doi.org/10.1186/s13059-016-0939-7)\n",
    "* Exclude assays with:\n",
    "    * LOD (limit of detection) >= 40\n",
    "* Exclude cells with:\n",
    "    * >70 failed assays\n",
    "    * B2M >= 13\n",
    "    * GAPDH >= 15\n",
    "    * Cells with mean Ct > 20\n",
    "* Norm to average of [B2M & GAPDH]\n",
    "* Expression = 2^-(NormCt)\n",
    "* Exclude HKgenes\n",
    "\n",
    "Going with Beth's method because it's the most thoroughly described.\n",
    "Might also gofor quantile nomrlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
