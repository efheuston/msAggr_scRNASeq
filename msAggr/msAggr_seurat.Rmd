---
title: "msAggr_seurat"
output: html_notebook
---

Creating new pipeline using seurat v4.0.2 available 2021.06.23  
Important notes:

* FILTERING on `percent.mt`, but NOT regressing on `percent.mt`
* Regressing on `nCounts_RNA` and `nFeature_RNA`

Load libraries required for Seuratv4

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_knit$set(root.dir = "~/Desktop/10XGenomicsData/msAggr_scRNASeq/")
library(dplyr)
library(Seurat)
library(patchwork)
library(ggplot2)
# library(clustree)
```
store session info
```{r}
sink("msAggr_seurat-v1.20210623")
sessionInfo()
sink()
```

# A note about using SCTransform versus `ScaleData`
https://bioconductor.org/packages/3.10/workflows/vignettes/simpleSingleCell/inst/doc/batch.html#62_for_gene-based_analyses
>You can also normalize and scale data for the RNA assay. There are numerous resources on this, but Aaron Lun describes why the original log-normalized values should be used for DE and visualizations of expression quite well here:
>
>For gene-based procedures like differential expression (DE) analyses or gene network construction, it is desirable to use the original log-expression values or counts. The corrected values are only used to obtain cell-level results such as clusters or trajectories. Batch effects are handled explicitly using blocking terms or via a meta-analysis across batches. We do not use the corrected values directly in gene-based analyses, for various reasons:
>
>It is usually inappropriate to perform DE analyses on batch-corrected values, due to the failure to model the uncertainty of the correction. This usually results in loss of type I error control, i.e., more false positives than expected.
>
>The correction does not preserve the mean-variance relationship. Applications of common DE methods like edgeR or limma are unlikely to be valid.
>
>Batch correction may (correctly) remove biological differences between batches in the course of mapping all cells onto a common coordinate system. Returning to the uncorrected expression values provides an opportunity for detecting such differences if they are of interest. Conversely, if the batch correction made a mistake, the use of the uncorrected expression values provides an important sanity check.
>
>In addition, the normalized values in SCT and integrated assays don't necessary correspond to per-gene expression values anyway, rather containing residuals (in the case of the scale.data slot for each).



Mess with how to load 4 cell populations into single seurat object



SET SEED?????!!!!!

## Set global variables

```{r}
projectName <- "msAggr"
jackstraw.dim <- 40
```



```{r}
source("msAggr_AnalysisCode/read_10XGenomics_data.R")
source("msAggr_AnalysisCode/PercentVariance.R")
```


```{r}
setwd("../cellRanger/") # temporarily changing wd only works if you run the entire chunk at once
data_file.list <- read_10XGenomics_data(sample.list = c("LSKm2", "CMPm2", "MEPm", "GMPm"))
data.object<-Read10X(data_file.list)
```



```{r}
seurat.object<- CreateSeuratObject(counts = data.object, min.cells = 3, min.genes = 200, project = projectName)
```

Clean up to free memory

```{r}
remove(data.object)
```


Add mitochondrial metadata and plot some basic features
```{r}
seurat.object[["percent.mt"]] <- PercentageFeatureSet(seurat.object, pattern = "^mt-")
VlnPlot(seurat.object, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3, pt.size = 0, fill.by = 'orig.ident', )
```


```{r fig.width=4, fig.height=2}
plot1 <- FeatureScatter(seurat.object, feature1 = "nCount_RNA", feature2 = "percent.mt", group.by = "orig.ident", pt.size = 0.01)
plot2 <- FeatureScatter(seurat.object, feature1 = "nCount_RNA", feature2 = "nFeature_RNA", group.by = "orig.ident", pt.size = 0.01)
plot1 + plot2
```


remove low quality cells
require: nFeature_RNA between 200 and 4000 (inclusive)
require: percent.mt <= 5

```{r}
print(paste("original object:", nrow(seurat.object@meta.data), "cells", sep = " "))
seurat.object <- subset(seurat.object, 
												subset = nFeature_RNA >=200 & 
													nFeature_RNA <= 4000 & 
													percent.mt <= 5
												)
print(paste("new object:", nrow(seurat.object@meta.data), "cells", sep = " "))
```



## Normalization

Struggling to wrap my head around this one. It seems that SCTransform is best for batch correction, but `NormalizeData` and `ScaleData` are best for DGE. Several vignettes have performed both

`selection.method	
How to choose top variable features. Choose one of :

vst: First, fits a line to the relationship of log(variance) and log(mean) using local polynomial regression (loess). Then standardizes the feature values using the observed mean and expected variance (given by the fitted line). Feature variance is then calculated on the standardized values after clipping to a maximum (see clip.max parameter).

mean.var.plot (mvp): First, uses a function to calculate average expression (mean.function) and dispersion (dispersion.function) for each feature. Next, divides features into num.bin (deafult 20) bins based on their average expression, and calculates z-scores for dispersion within each bin. The purpose of this is to identify variable features while controlling for the strong relationship between variability and average expression.

dispersion (disp): selects the genes with the highest dispersion values`




```{r}
seurat.object <- NormalizeData(seurat.object, normalization.method = "LogNormalize", scale.factor = 10000)
```





Find variable features
```{r fig.width = 5, fig.height = 2}
seurat.object <- FindVariableFeatures(seurat.object, selection.method = "vst", nfeatures = 2000)
top10 <- head(VariableFeatures(seurat.object), 10)
plot1 <- VariableFeaturePlot(seurat.object)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot1 + plot2
```

Scale data (linear transformation)

```{r}
all.genes <- rownames(seurat.object)
seurat.object <- ScaleData(seurat.object, features = all.genes, vars.to.regress = c("nCount_RNA", "nFeature_RNA"))
```


### Save progress

```{r}
save.image(file = paste0(projectName, '.RData'))
```


## PCA

linear dimensional reduction. Default are based on VariableFeatures, but can be changed

```{r}
seurat.object <- RunPCA(seurat.object, features = VariableFeatures(object = seurat.object))
```
Plot results
```{r fig.width=4, fig.height=4}
VizDimLoadings(seurat.object, dims = 1:6, nfeatures = 10, reduction = "pca", ncol = 2)
```

DimPlot colored by orig.ident
```{r}
DimPlot(seurat.object, reduction = "pca", group.by = "orig.ident")
```
Let's put in a concerted effort to pick the right dimensionality using the newest software
```{r}
# jackstraw.dim <- 40
# seurat.object <- JackStraw(seurat.object, num.replicate = 100, dims = jackstraw.dim) #runs ~50 min
# seurat.object <- ScoreJackStraw(seurat.object, dims = 1:jackstraw.dim)
# save.image(paste0(projectName, ".RData"))
```
Draw dim.reduction plots
```{r}
# JackStrawPlot(seurat.object, dims = 25:36)
```
```{r, figures-side, fig.show='hold', out.width="50%"}
ElbowPlot(seurat.object, ndims = 50)
percent.variance(seurat.object@reductions$pca@stdev)
```
Number of PCs describing X% of variance
```{r}
tot.var <- percent.variance(seurat.object@reductions$pca@stdev, plot.var = FALSE, return.val = TRUE)
paste0("Num pcs for 80% variance:", length(which(cumsum(tot.var) <= 80)))
paste0("Num pcs for 85% variance:", length(which(cumsum(tot.var) <= 85)))
paste0("Num pcs for 90% variance:", length(which(cumsum(tot.var) <= 90)))
paste0("Num pcs for 95% variance:", length(which(cumsum(tot.var) <= 95)))

```

## Add cluster IDs from Seurat v1

Exported cell IDs for clusters 3, 17, 10, 11 from Seurat v1. Will add these IDs as a metadata column.  
Create column "clust.ID" and populate with 0's. Then import IDs for clusters
```{r}
clust3.cells <- read.table(file = "Seuratv1_clusterCellIDs/cluster3cellIDs.txt", col.names = "clust03")
clust3.cells <- sapply(clust3.cells, function(x) paste0(gsub("CMP", "CMPm2", x), "-1"))
clust17.cells <- read.table(file = "Seuratv1_clusterCellIDs/cluster17cellIDs.txt", col.names = "clust17")
clust17.cells <- sapply(clust17.cells, function(x) paste0(gsub("CMP", "CMPm2", x), "-1"))
clust10.cells <- read.table(file = "Seuratv1_clusterCellIDs/cluster10cellIDs.txt", col.names = "clust10")
clust10.cells <- sapply(clust10.cells, function(x) paste0(gsub("CMP", "CMPm2", x), "-1"))
clust11.cells <- read.table(file = "Seuratv1_clusterCellIDs/cluster11cellIDs.txt", col.names = "clust11")
clust11.cells <- sapply(clust11.cells, function(x) paste0(gsub("CMP", "CMPm2", x), "-1"))
```

Add new metadata column and map new ids
```{r}
seurat.object@meta.data['clust.ID'] <- 0
seurat.object@meta.data$clust.ID[rownames(seurat.object@meta.data) %in% clust3.cells] <- 3
seurat.object@meta.data$clust.ID[rownames(seurat.object@meta.data) %in% clust17.cells] <- 17
seurat.object@meta.data$clust.ID[rownames(seurat.object@meta.data) %in% clust10.cells] <- 10
seurat.object@meta.data$clust.ID[rownames(seurat.object@meta.data) %in% clust11.cells] <- 11
```

do numbers make sense (we don't expect the count to b exactly the same as the numbers in the original cluster)?
```{r}
nrow(seurat.object@meta.data[seurat.object@meta.data$clust.ID == 10,])
nrow(seurat.object@meta.data[seurat.object@meta.data$clust.ID == 11,])
nrow(seurat.object@meta.data[seurat.object@meta.data$clust.ID == 17,])
nrow(seurat.object@meta.data[seurat.object@meta.data$clust.ID == 3,])
```

make enough sense!



# DGE

Let's do some cluster analyses and see if we can find these populations in our new analysis.
## Ideal resolution...? (Is this a thing?)
### Color palette
```{r}
color.palette <- c(
	"coral",
	"chartreuse4",
	"goldenrod1",
	"cadetblue1",
	"burlywood",
	"brown",
	"brown1",
	"blue",
	"blue4",
	"azure3",
	"aquamarine",
	"antiquewhite",
	"cadetblue",
	"gold3",
	"black",
	"darkgreen",
	"deeppink",
	"darkviolet",
	"darkturquoise",
	"darkslategray",
	"darksalmon",
	"darkorchid1",
	"darkolivegreen2",
	"forestgreen",
	"dodgerblue",
	"green",
	"lightpink",
	"lightcoral",
	"khaki1",
	"maroon",
	"peru",
	"lightseagreen",
	"lightsalmon",
	"plum",
	"moccasin",
	"tan",
	"tan1", 
	"red", 
	"purple",
	"khaki4",
	"black", 
	"plum4"
)
```

# Total var 90%
## Neighborhood and umap
set total.var <- 90%
```{r}
tot.var <- percent.variance(seurat.object@reductions$pca@stdev, plot.var = FALSE, return.val = TRUE)
ndims <- length(which(cumsum(tot.var) <= 90))
print(ndims)

seurat.object <- FindNeighbors(seurat.object, dims = 1:ndims)
seurat.object <- FindClusters(seurat.object, resolution = 0.5)
seurat.object <- RunUMAP(seurat.object, dims = 1: ndims)

# saveRDS(seurat.object, file = paste0(projectName, "_dim", ndims, ".RDS"))
```
Plot UMAP

```{r}
for(x in c(0.5, 1, 1.5, 2, 2.5)){
	seurat.object <- FindClusters(seurat.object, resolution = x)
}
```

```{r}
for (meta.col in colnames(seurat.object@meta.data)){
	if(grepl(pattern = ("RNA_snn_res"), x = meta.col)==TRUE){
		myplot <- DimPlot(seurat.object, 
											group.by = meta.col,
											reduction = "umap", 
											cols = color.palette
											) + 
			ggtitle(paste0(projectName, " dim", ndims, "res", gsub("RNA_snn_res", "", meta.col) ))
		plot(myplot)
	}
}
```


Generate statistics for each cluster/resolution combo
```{r}
current_res <- 'RNA_snn_res.0.5'

cluster_ids <- sort(unique(seurat.object@meta.data[,current_res]))
counts_df <- data.frame(matrix(nrow = length(cluster_ids), ncol = 4))
rownames(counts_df) <- cluster_ids
colnames(counts_df) <- c("LSKm2", "CMPm2", "MEPm", "GMPm")
for(id in cluster_ids){
	cell_value <- nrow(seurat.object@meta.data[(seurat.object@meta.data[current_res] == id) & 
																						 	(seurat.object@meta.data$orig.ident == "LSKm2"),])
	counts_df[id, "LSKm2"] = cell_value
	cell_value <- nrow(seurat.object@meta.data[(seurat.object@meta.data[current_res] == id) & 
																						 	(seurat.object@meta.data$orig.ident == "LSKm2"),])
	counts_df[id, "CMPm2"] = cell_value
	cell_value <- nrow(seurat.object@meta.data[(seurat.object@meta.data[current_res] == id) & 
																						 	(seurat.object@meta.data$orig.ident == "MEPm"),])
	counts_df[id, "MEPm"] = cell_value
	cell_value <- nrow(seurat.object@meta.data[(seurat.object@meta.data[current_res] == id) & 
																						 	(seurat.object@meta.data$orig.ident == "GMPm"),])
	counts_df[id, "GMPm"] = cell_value

}

```






For each resolution, what percentage of cells in each cluster are enriched for one of our clust.IDs?



Test: what percentage of each new clusterID matches one of the older clusters?
```{r}
for (meta.col in colnames(seurat.object@meta.data)){
	if(grepl(pattern = ("RNA_snn_res"), x = meta.col)==TRUE){
		new.clusters <- sort(as.numeric(levels(seurat.object@meta.data[[meta.col]])))
		enrich.df <- data.frame(matrix(ncol = 4, nrow = length(new.clusters)))
		colnames(enrich.df) <- c(3, 17, 10, 11)
		rownames(enrich.df) <- new.clusters
		meta.df <- seurat.object@meta.data
		for(row.id in rownames(enrich.df)){
			tot.clus <- nrow(meta.df[meta.df[[meta.col]] == row.id,])
			for(col.id in colnames(enrich.df)){
				num.x <- nrow(meta.df[(meta.df[[meta.col]] == row.id) & (meta.df$clust.ID == col.id),])
				pct.x <- as.integer(num.x / tot.clus *100)
				# print(pct.x)
				enrich.df[row.id, col.id] <- pct.x
			}
		}
		colnames(enrich.df) <- sapply(colnames(enrich.df), function(x) paste0("oldcluster", x))
		rownames(enrich.df) <- sapply(rownames(enrich.df), function(x) paste0("newcluster", x))
		try{xlsx::write.xlsx(enrich.df, file = paste0("PctOfNewClustersOverlappingOldClusters_", projectName, "_dim", ndims, ".xlsx"), sheetName = paste0(gsub("RNA_snn_", "", meta.col)), append = TRUE)}
		print(enrich.df)
	}
}

```
Absolutely terrible overlap, no enrichment of any of these across the new clustering algorithm. Maybe should try 95% variation covered

## Find old cells on UMAP

time for the super scarey moment to see if the cells from seuratv1 still cluster together on in seurat v4

```{r fig.width = 4}
DimPlot(seurat.object,
				reduction = "umap",
				group.by = "clust.ID", 
				# split.by = "orig.ident",
				cols = c("gray", "orange", "blue", "red", "green"),)
```
```{r fig.width = 4}
DimPlot(seurat.object,
				reduction = "umap",
				group.by = "orig.ident", 
				split.by = "clust.ID",
				cols = c("gray", "orange", "blue", "red", "green"),)
```


# Total var 95%
## Neighborhood and umap
set total.var <- 95%
```{r}
tot.var <- percent.variance(seurat.object@reductions$pca@stdev, plot.var = FALSE, return.val = TRUE)
ndims <- length(which(cumsum(tot.var) <= 95))
print(ndims)

seurat.object <- FindNeighbors(seurat.object, dims = 1:ndims)
seurat.object <- FindClusters(seurat.object, resolution = 0.5)
seurat.object <- RunUMAP(seurat.object, dims = 1: ndims)

# saveRDS(seurat.object, file = paste0(projectName, "_dim", ndims, ".RDS"))
```
Plot UMAP

```{r}
for(x in c(0.5, 1, 1.5, 2, 2.5)){
	seurat.object <- FindClusters(seurat.object, resolution = x)
}
```



For each resolution, what percentage of cells in each cluster are enriched for one of our clust.IDs?


Test: what percentage of each new clusterID matches one of the older clusters?
```{r}
for (meta.col in colnames(seurat.object@meta.data)){
	if(grepl(pattern = ("RNA_snn_res"), x = meta.col)==TRUE){
		new.clusters <- sort(as.numeric(levels(seurat.object@meta.data[[meta.col]])))
		enrich.df <- data.frame(matrix(ncol = 4, nrow = length(new.clusters)))
		colnames(enrich.df) <- c(3, 17, 10, 11)
		rownames(enrich.df) <- new.clusters
		meta.df <- seurat.object@meta.data
		for(row.id in rownames(enrich.df)){
			tot.clus <- nrow(meta.df[meta.df[[meta.col]] == row.id,])
			for(col.id in colnames(enrich.df)){
				num.x <- nrow(meta.df[(meta.df[[meta.col]] == row.id) & (meta.df$clust.ID == col.id),])
				pct.x <- as.integer(num.x / tot.clus *100)
				# print(pct.x)
				enrich.df[row.id, col.id] <- pct.x
			}
		}
		colnames(enrich.df) <- sapply(colnames(enrich.df), function(x) paste0("oldcluster", x))
		rownames(enrich.df) <- sapply(rownames(enrich.df), function(x) paste0("newcluster", x))
		xlsx::write.xlsx(enrich.df, file = paste0("PctOfNewClustersOverlappingOldClusters_", projectName, "_dim", ndims, ".xlsx"), sheetName = paste0(gsub("RNA_snn_", "", meta.col)), append = TRUE)
		print(enrich.df)
	}
}

```
Absolutely terrible overlap, no enrichment of any of these across the new clustering algorithm. Maybe should try 95% variation covered

## Find old cells on UMAP

time for the super scarey moment to see if the cells from seuratv1 still cluster together on in seurat v4

```{r fig.width = 2}
DimPlot(seurat.object,
				reduction = "umap",
				group.by = "clust.ID", 
				pt.size = .1,
				# split.by = "orig.ident",
				cols = c("gray", "orange", "blue", "red", "green"),)
```
```{r fig.width = 4}
DimPlot(seurat.object,
				reduction = "umap",
				group.by = "orig.ident", 
				split.by = "clust.ID",
				cols = c("gray", "orange", "blue", "red", "green"),)
```



### Gene expression of old clustrs on new map
Let's see if we can get some gene expression profiles on these...
```{r, fig.height=10, fig.width=18}
gene.list <- c("Gata1", "Gata2", "Pf4", "Dntt", "Mpo", "Meis1", "Irf8", "Elane", "Fli1", "Zfpm1")
VlnPlot(seurat.object, features = gene.list, group.by = "clust.ID", pt.size = 0.01, cols = c("gray", "orange", "blue", "red", "green"))
```


## Evaluate cluster stability
Must ensure we have the right cluster stability, that is, cells that start in the same cluster tend to stay in the same cluster. If your data is over-clustered, cells will bounce between groups.

Following [this tutorial by Matt O.].https://towardsdatascience.com/10-tips-for-choosing-the-optimal-number-of-clusters-277e93d72d92.

### Clustree
Previously my favourite has been Clustree, which gives a nice visual
NB: For some reason `clustree::clustree()` didn't work, whereas `library(clustree)` followed by `clustree()` did.

```{r fig.height=5}
clustree(seurat.object, prefix = "RNA_snn_res.", node_colour = "sc3_stability") + 
	scale_color_continuous(low = 'red3', high = 'white')
```



```{r fig.height=5}
clustree(seurat.object, prefix = "RNA_snn_res.", expres = 'data', node_colour = "sc3_stability") + 
	scale_color_continuous(low = 'red3', high = 'white')
```


```{r fig.height=5}
clustree(seurat.object, prefix = "RNA_snn_res.", expres = 'scale.data', node_colour = "sc3_stability") + 
	scale_color_continuous(low = 'red3', high = 'white')
```



```{r fig.height=5}
clustree(seurat.object, prefix = "RNA_snn_res.", expres = 'counts', node_colour = "sc3_stability") + 
	scale_color_continuous(low = 'red3', high = 'white')
```




These data suggest that node stability is aweful! Need to figure out if this is a dimensional reduction error or a clustering error.


# Why are clusters so unstable?
Differences could include:
* cells in each population (cellranger v6 includes more cells than cellranger v1, especially in MEP)
* dimensionality is incorrect
* ScaleData didnt account for regression factors (e.g., "nCounts_RNA" or "nFeatures_RNA")
* Did not consider cell cycle
* Incorrect normalization/scaling method
* Clustering is too strict or not strict enough
* neighborhood analysis used wrong parameters
* Should include mitoC filter (there's a chunk of MEP w/ mitoC @ ~40%)
* SCTransform accounts better for sources of variability

```{r}
# Number of filtered cells left in each pop
sapply(c("LSKm2", "CMPm2", "MEPm", "GMPm"), function(x) (c(nrow(seurat.object@meta.data[seurat.object@meta.data$orig.ident == x,]))))
```

```{r}
for (x in c("LSKm2", "CMPm2", "MEPm", "GMPm")){
	h = hist(seurat.object@meta.data[seurat.object@meta.data$orig.ident == x, 'percent.mt'], breaks = 30, plot = FALSE)
	h$density = h$counts/sum(h$counts)*100
	plot(h,freq=FALSE, main =  paste(x, "percent mitoC"), xlab = "percent mitoC", ylab = "Frequency")
}
```

Looks like MEPm is the only sample with that huge MitoC % lump @ 40%. What do these cells look like, otherwise?

```{r fig.width=5}
VlnPlot(subset(seurat.object, subset = orig.ident == "MEPm"), 
				features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 1, pt.size = 0, fill.by = 'ident', flip = TRUE)
```
Save dim36 as is and try clustering analysis @ dim24
```{r}
saveRDS(seurat.object, file = "msAggr_AnalysisCode/msAggr_dim36.rds")
```



# Repeat clustering with dim24
One possibility is that I've included too many dimensions. Will see if 90% increases stability.

```{r}
seurat.object <- FindNeighbors(seurat.object, dims = 1:24)
seurat.object <- FindClusters(seurat.object, resolution = 0.5)
seurat.object <- RunUMAP(seurat.object, dims = 1:24)
```

Save object
```{r}
saveRDS(seurat.object, file = "msAggr_dim24.rds")
```




```{r}
for (meta.col in colnames(seurat.object@meta.data)){
	if(grepl(pattern = ("RNA_snn_res"), x = meta.col)==TRUE){
		myplot <- DimPlot(seurat.object, 
											group.by = meta.col,
											reduction = "umap", 
											cols = colorRamps::primary.colors(n = length(levels(seurat.object@meta.data[[meta.col]])))
											) + 
			ggtitle(paste0("msAggr dim36 res", gsub("RNA_snn_res", "", meta.col) ))
		plot(myplot)
	}
}
```




## Evaluate cluster stability
Must ensure we have the right cluster stability, that is, cells that start in the same cluster tend to stay in the same cluster. If your data is over-clustered, cells will bounce between groups.

Following [this tutorial by Matt O.].https://towardsdatascience.com/10-tips-for-choosing-the-optimal-number-of-clusters-277e93d72d92.

### Clustree
Previously my favourite has been Clustree, which gives a nice visual
NB: For some reason `clustree::clustree()` didn't work, whereas `library(clustree)` followed by `clustree()` did.

```{r fig.height=5}
clustree(seurat.object, prefix = "RNA_snn_res.", node_colour = "sc3_stability") + 
	scale_color_continuous(low = 'red3', high = 'white')
```

Think I'll explore regression factors using SCTransform in new document.
